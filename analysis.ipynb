{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(model_type, cm, target_names, title, cmap=None, normalize=True):\n",
    "    \"\"\"\n",
    "    link: https://www.kaggle.com/grfiv4/plot-a-confusion-matrix \n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "    \"\"\"\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\n\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    filename = './'+ model_type + '/'+ model_type + '_confusion_matrix.png'\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_graphs(emotion_keys, true_counts, pred_counts, model_type):\n",
    "    index = np.arange(len(emotion_keys))\n",
    "    \n",
    "    # Only true labels\n",
    "    plt.bar(index, true_counts)\n",
    "    plt.xticks(index, emotion_keys)\n",
    "    plt.ylabel('Count')\n",
    "    plt.ylim(0, 800)\n",
    "    plt.title('True Labels by Mask Adherence')\n",
    "    filename = './'+ model_type + '/'+ model_type + '_true_labels_bar.png'\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "    \n",
    "    # Only predicted labels\n",
    "    plt.bar(index, pred_counts)\n",
    "    plt.xticks(index, emotion_keys)\n",
    "    plt.ylabel('Count')\n",
    "    plt.ylim(0, 800)\n",
    "    plt.title('Predicted Labels by Mask Adherence')\n",
    "    filename = './'+ model_type + '/'+ model_type + '_predicted_labels_bar.png'\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "    \n",
    "    # Both labels\n",
    "    fig, ax = plt.subplots()\n",
    "    bar_width = 0.35\n",
    "    opacity = 0.8\n",
    "\n",
    "    rects1 = plt.bar(index, true_counts, bar_width, alpha=opacity, color='b', label='True Labels')\n",
    "    rects2 = plt.bar(index + bar_width, pred_counts, bar_width, alpha=opacity, color='g', label='Predicted Labels')\n",
    "\n",
    "    plt.xlabel('Mask Adherence')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('True Labels and Predicted Labels')\n",
    "    plt.xticks(index + bar_width / 2, emotion_keys)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    filename = './'+ model_type + '/'+ model_type + '_both_labels_bar.png'\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plots(labels, predictions, emotion_keys, model_type):\n",
    "    matrix = confusion_matrix(labels, predictions)\n",
    "    \n",
    "    true_counts = np.zeros((len(emotion_keys)))\n",
    "    pred_counts = np.zeros((len(emotion_keys)))\n",
    "    \n",
    "    for val in range(len(emotion_keys)):\n",
    "        true_counts[val] = np.count_nonzero(labels == val)\n",
    "        pred_counts[val] = np.count_nonzero(predictions == val)\n",
    "    \n",
    "    plot_confusion_matrix(model_type   = model_type,\n",
    "                          cm           = matrix,\n",
    "                          normalize    = True,\n",
    "                          target_names = emotion_keys,\n",
    "                          title        = \"Confusion Matrix\")\n",
    "    \n",
    "    plot_bar_graphs(emotion_keys, true_counts, pred_counts, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['no mask', 'mask', 'incorrect mask']\n",
    "labels = np.load('./results/y_test.npy')\n",
    "predictions = np.load('./results/y_test_pred.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.argmax(labels, axis=1)\n",
    "predictions = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 2, 1, 1, 1, 1, 2, 0, 2, 1, 2,\n",
       "        1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 0, 2, 1, 2, 2, 0, 0, 0, 2, 2, 2,\n",
       "        2, 1, 1, 2, 1, 0, 1, 0, 2, 1, 2, 2, 0, 0, 1, 2, 0, 1, 0, 2, 0, 0,\n",
       "        0, 2, 0, 1, 1, 1, 2, 1, 0, 1, 2, 2, 1, 0, 1, 2, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 1, 0, 2, 0, 2, 1, 0, 0, 0, 1, 1, 0, 2, 0, 0, 0, 1, 2, 0, 2,\n",
       "        0, 0, 0, 1, 0, 1, 2, 0, 1, 1, 1, 0, 0, 2, 0, 2, 0, 2, 1, 0, 1, 1,\n",
       "        2, 2, 0, 0, 2, 2, 0, 0, 2, 2, 2, 1, 2, 2, 0, 1, 0, 0, 2, 2, 2, 2,\n",
       "        1, 0, 2, 1, 1, 1, 2, 0, 1, 2, 2, 1, 2, 1, 0, 0, 2, 1, 2, 1, 2, 2,\n",
       "        1, 2, 1, 2, 0, 1, 2, 2, 2, 1, 2, 2, 1, 0, 1, 2, 0, 1, 0, 2, 1, 2,\n",
       "        2, 1, 1, 1, 2, 0]),\n",
       " array([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 2, 1, 1, 1, 1, 2, 0, 2, 1, 1,\n",
       "        1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 0, 0, 1, 2, 2, 0, 0, 0, 2, 2, 2,\n",
       "        0, 1, 2, 2, 1, 0, 2, 0, 2, 1, 2, 2, 0, 2, 1, 2, 0, 2, 0, 2, 0, 0,\n",
       "        0, 2, 0, 1, 1, 1, 2, 1, 0, 1, 2, 2, 1, 0, 1, 2, 0, 1, 2, 0, 0, 0,\n",
       "        0, 0, 1, 0, 2, 0, 0, 1, 0, 0, 0, 1, 1, 0, 2, 0, 0, 0, 1, 0, 2, 2,\n",
       "        0, 0, 1, 1, 0, 2, 2, 0, 1, 1, 1, 0, 0, 2, 0, 2, 0, 2, 2, 0, 1, 1,\n",
       "        2, 2, 0, 0, 2, 2, 0, 0, 2, 2, 2, 1, 2, 2, 0, 1, 0, 0, 2, 2, 0, 2,\n",
       "        1, 0, 2, 1, 1, 1, 2, 0, 1, 0, 2, 1, 2, 1, 0, 0, 2, 1, 2, 1, 2, 2,\n",
       "        1, 2, 1, 2, 0, 1, 2, 2, 2, 1, 2, 2, 0, 0, 1, 2, 0, 1, 2, 2, 1, 2,\n",
       "        2, 1, 1, 1, 2, 0]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9117647058823529"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_type = 'cnn_test'\n",
    "create_plots(labels, predictions, keys, model_type)\n",
    "accuracy_score(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
